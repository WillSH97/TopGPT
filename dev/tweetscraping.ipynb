{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c17a34b",
   "metadata": {},
   "source": [
    "# Scraping Andrew's Tweets :')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a7c3ee",
   "metadata": {},
   "source": [
    "NOTE: this code seems to only run correctly on google colab - some new bug for snscrape introduced by Elon. Don't blame me, blame him. We need to run the dev version of snscrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26b4c0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/JustAnotherArchivist/snscrape.git\n",
      "  Cloning https://github.com/JustAnotherArchivist/snscrape.git to c:\\users\\willi\\appdata\\local\\temp\\pip-req-build-7thk_q4n\n",
      "  Resolved https://github.com/JustAnotherArchivist/snscrape.git to commit 786815dd05681e2421cd03aa9acf5ab5c773bce9\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: filelock in c:\\users\\willi\\anaconda3\\lib\\site-packages (from snscrape==0.6.2.20230321.dev13+g786815d) (3.9.0)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\willi\\anaconda3\\lib\\site-packages (from snscrape==0.6.2.20230321.dev13+g786815d) (2.28.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\willi\\anaconda3\\lib\\site-packages (from snscrape==0.6.2.20230321.dev13+g786815d) (4.11.1)\n",
      "Requirement already satisfied: lxml in c:\\users\\willi\\anaconda3\\lib\\site-packages (from snscrape==0.6.2.20230321.dev13+g786815d) (4.9.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\willi\\anaconda3\\lib\\site-packages (from beautifulsoup4->snscrape==0.6.2.20230321.dev13+g786815d) (2.3.2.post1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\willi\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape==0.6.2.20230321.dev13+g786815d) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\willi\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape==0.6.2.20230321.dev13+g786815d) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\willi\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape==0.6.2.20230321.dev13+g786815d) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\willi\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape==0.6.2.20230321.dev13+g786815d) (2.0.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\willi\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape==0.6.2.20230321.dev13+g786815d) (1.7.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/JustAnotherArchivist/snscrape.git 'C:\\Users\\willi\\AppData\\Local\\Temp\\pip-req-build-7thk_q4n'\n"
     ]
    }
   ],
   "source": [
    "!pip3 install git+https://github.com/JustAnotherArchivist/snscrape.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8e9a7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e502a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after 20 empty pages\n"
     ]
    }
   ],
   "source": [
    "# Created a list to append all tweet attributes(data)\n",
    "attributes_container = []\n",
    "\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list. \n",
    "# Arbitrarily stopping loop at 9999 (although he has less than 2000 tweets as of 27/05/23)\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('from:Cobratate').get_items()):\n",
    "    if i>9999:\n",
    "        break\n",
    "    attributes_container.append([tweet.date, tweet.likeCount, tweet.sourceLabel, tweet.rawContent])\n",
    "    \n",
    "# Creating a dataframe from the tweets list above \n",
    "tweets_df = pd.DataFrame(attributes_container, columns=[\"Date Created\", \"Number of Likes\", \"Source of Tweet\", \"Tweets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "615ed3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Created</th>\n",
       "      <th>Number of Likes</th>\n",
       "      <th>Source of Tweet</th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-27 12:38:54+00:00</td>\n",
       "      <td>3927</td>\n",
       "      <td>None</td>\n",
       "      <td>If they’re truly sorry, truly forgive them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-05-27 10:52:39+00:00</td>\n",
       "      <td>4329</td>\n",
       "      <td>None</td>\n",
       "      <td>https://t.co/72oMayAmig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-05-27 10:00:34+00:00</td>\n",
       "      <td>963</td>\n",
       "      <td>None</td>\n",
       "      <td>When’s the last time you prevented the negativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-05-27 09:23:36+00:00</td>\n",
       "      <td>870</td>\n",
       "      <td>None</td>\n",
       "      <td>https://t.co/hCv8hxSm4p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-05-26 23:17:03+00:00</td>\n",
       "      <td>29969</td>\n",
       "      <td>None</td>\n",
       "      <td>Allahu Akbar https://t.co/9TWIyi9GKe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>2022-11-19 09:28:14+00:00</td>\n",
       "      <td>45525</td>\n",
       "      <td>None</td>\n",
       "      <td>@MasculinePeak Listen to me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>2022-11-19 08:28:28+00:00</td>\n",
       "      <td>176915</td>\n",
       "      <td>None</td>\n",
       "      <td>I was banned on every single app known to man....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>2022-11-19 02:34:43+00:00</td>\n",
       "      <td>253926</td>\n",
       "      <td>None</td>\n",
       "      <td>I am waiting for the free minds. \\n\\nhttps://t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>2022-11-19 02:00:02+00:00</td>\n",
       "      <td>59934</td>\n",
       "      <td>None</td>\n",
       "      <td>I have no fear of death. More importantly, I d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>2022-11-18 18:43:06+00:00</td>\n",
       "      <td>131804</td>\n",
       "      <td>None</td>\n",
       "      <td>Mastery is a funny thing. \\n\\nIt’s almost as i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1774 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date Created  Number of Likes Source of Tweet  \\\n",
       "0    2023-05-27 12:38:54+00:00             3927            None   \n",
       "1    2023-05-27 10:52:39+00:00             4329            None   \n",
       "2    2023-05-27 10:00:34+00:00              963            None   \n",
       "3    2023-05-27 09:23:36+00:00              870            None   \n",
       "4    2023-05-26 23:17:03+00:00            29969            None   \n",
       "...                        ...              ...             ...   \n",
       "1769 2022-11-19 09:28:14+00:00            45525            None   \n",
       "1770 2022-11-19 08:28:28+00:00           176915            None   \n",
       "1771 2022-11-19 02:34:43+00:00           253926            None   \n",
       "1772 2022-11-19 02:00:02+00:00            59934            None   \n",
       "1773 2022-11-18 18:43:06+00:00           131804            None   \n",
       "\n",
       "                                                 Tweets  \n",
       "0           If they’re truly sorry, truly forgive them.  \n",
       "1                               https://t.co/72oMayAmig  \n",
       "2     When’s the last time you prevented the negativ...  \n",
       "3                               https://t.co/hCv8hxSm4p  \n",
       "4                  Allahu Akbar https://t.co/9TWIyi9GKe  \n",
       "...                                                 ...  \n",
       "1769                       @MasculinePeak Listen to me.  \n",
       "1770  I was banned on every single app known to man....  \n",
       "1771  I am waiting for the free minds. \\n\\nhttps://t...  \n",
       "1772  I have no fear of death. More importantly, I d...  \n",
       "1773  Mastery is a funny thing. \\n\\nIt’s almost as i...  \n",
       "\n",
       "[1774 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7762496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
    "tweets_df.to_csv(parent_dir + '/twitterdata/andrew_tate.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
